{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b9ee9e5",
   "metadata": {},
   "source": [
    "# 参数解析器\n",
    "**这里我们使用现成的标准库argparse来进行参数解析任务**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91ccd3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "警告：未识别参数: ['accurate']\n",
      "开始处理: input.jpg\n",
      "输出文件: output.jpg\n",
      "缩放比例: 1.0\n",
      "输出格式: png\n",
      "裁剪参数: [10, 10, 100, 100]\n",
      "应用特效: ['blur', 'sharpen']\n",
      "亮度调整: 20\n",
      "处理模式: fast\n",
      "[✓] 已处理图片并输出至：output.jpg\n"
     ]
    }
   ],
   "source": [
    "import argparse,sys\n",
    "\n",
    "\n",
    "# 创建 ArgumentParser 对象，描述用于生成 --help 的说明文字\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='图像处理工具：支持裁剪、缩放、调整亮度、指定输出格式等功能'\n",
    ")\n",
    "\n",
    "# ===== 1. 位置参数（必填） =====\n",
    "parser.add_argument(\n",
    "    'input_file',\n",
    "    type=str,\n",
    "    help='输入图片路径（必填）'\n",
    ")\n",
    "\n",
    "# ===== 2. 基本可选参数 =====\n",
    "parser.add_argument(\n",
    "    '-o', '--output',\n",
    "    type=str,\n",
    "    default='output.jpg',\n",
    "    help='输出文件路径（默认：output.jpg）'\n",
    ")\n",
    "\n",
    "# ===== 3. 类型控制与默认值 =====\n",
    "parser.add_argument(\n",
    "    '--scale',\n",
    "    type=float,\n",
    "    default=1.0,\n",
    "    help='缩放比例，例如 0.5 表示缩小一半'\n",
    ")\n",
    "\n",
    "# ===== 4. 布尔值（action） =====\n",
    "parser.add_argument(\n",
    "    '-v', '--verbose',\n",
    "    action='store_true',\n",
    "    help='是否打印详细过程信息'\n",
    ")\n",
    "\n",
    "# ===== 5. 选项限制（choices） =====\n",
    "parser.add_argument(\n",
    "    '--format',\n",
    "    choices=['jpg', 'png', 'bmp'],\n",
    "    default='jpg',\n",
    "    help='输出图片格式（可选：jpg, png, bmp）'\n",
    ")\n",
    "\n",
    "# ===== 6. 多值输入（nargs） =====\n",
    "parser.add_argument(\n",
    "    '--crop',\n",
    "    type=int,\n",
    "    nargs=4,\n",
    "    metavar=('X', 'Y', 'W', 'H'),\n",
    "    help='裁剪区域，格式为 X Y W H'\n",
    ")\n",
    "\n",
    "# ===== 7. 多次追加（append） =====\n",
    "parser.add_argument(\n",
    "    '--effect',\n",
    "    action='append',\n",
    "    help='多次应用图像效果（如 blur, sharpen, grayscale）'\n",
    ")\n",
    "\n",
    "# ===== 8. 参数别名（dest） =====\n",
    "parser.add_argument(\n",
    "    '--lightness',\n",
    "    dest='brightness',\n",
    "    type=int,\n",
    "    default=0,\n",
    "    help='亮度调整（-100 到 100）'\n",
    ")\n",
    "\n",
    "# ===== 9. 可选位置参数（nargs=\"?\"+default） =====\n",
    "parser.add_argument(\n",
    "    'mode',\n",
    "    nargs='?',\n",
    "    choices=['fast', 'accurate'],\n",
    "    default='fast',\n",
    "    help='处理模式（默认：fast）'\n",
    ")\n",
    "\n",
    "# ===== 10. 解析参数 =====\n",
    "args, unknown = parser.parse_known_args([\n",
    "    'input.jpg',\n",
    "    '--format', 'png',\n",
    "    '-v',\n",
    "    '--effect', 'blur',\n",
    "    '--effect', 'sharpen',\n",
    "    '--crop', '10', '10', '100', '100',\n",
    "    '--lightness', '20',\n",
    "    'accurate'\n",
    "]\n",
    ")\n",
    "\n",
    "if unknown:\n",
    "    print(\"警告：未识别参数:\", unknown)\n",
    "\n",
    "\n",
    "# ===== 11. 使用参数（模拟处理） =====\n",
    "if args.verbose:\n",
    "    print(f'开始处理: {args.input_file}')\n",
    "    print(f'输出文件: {args.output}')\n",
    "    print(f'缩放比例: {args.scale}')\n",
    "    print(f'输出格式: {args.format}')\n",
    "    print(f'裁剪参数: {args.crop}')\n",
    "    print(f'应用特效: {args.effect}')\n",
    "    print(f'亮度调整: {args.brightness}')\n",
    "    print(f'处理模式: {args.mode}')\n",
    "\n",
    "# 模拟输出\n",
    "print(f\"[✓] 已处理图片并输出至：{args.output}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9f7eee",
   "metadata": {},
   "source": [
    "# 了解YOLO模型的输入输出格式\n",
    "\n",
    "\n",
    "YOLO输入输出格式特点比较固定，主要是：\n",
    "\n",
    "\n",
    "## YOLO 输入格式\n",
    "\n",
    "\n",
    "* **格式：** 通常是三通道的RGB图像，`大小固定`（如YOLOv3常用的输入是 416×416 或 608×608），故，图像一般需要预处理：\n",
    "\n",
    "  1. 缩放到固定大小\n",
    "  2. 归一化（像素值通常归一化到0~~1或者-1~~1）\n",
    "  3. 转为模型接受的形状`shape`格式（如`[batch_size, channels, height, width]`）\n",
    "\n",
    "      | 参数                    | 说明                              | 具体举例             |\n",
    "      | --------------------- | ------------------------------- | ---------------- |\n",
    "      | **batch_size**（批量大小） | 一次送入模型的图片数量。YOLO支持批量输入，提高计算效率。  | `1` 表示只输入一张图     |\n",
    "      | **channels**（通道数）     | RGB,就是咱们说的三大基本色 | `3` 表示红绿蓝三通道     |\n",
    "      | **height**（高度）        |图片尺度                 | `416` 表示图像高416像素 |\n",
    "      | **width**（宽度）         | 图片尺度                  | `416` 表示图像宽416像素 |\n",
    "\n",
    "\n",
    "* **输入一般是张量（Tensor）形式**，具体格式视深度学习框架而定，Mindspore的是\n",
    "      \n",
    "    | MindSpore张量特性 | 说明                    |\n",
    "    | ------------- | --------------------- |\n",
    "    | 多维数组          | 表示数据的多维矩阵             |\n",
    "    | 支持多种dtype     | float32、int32等        |\n",
    "    | 有形状信息         | 通过 `.shape` 属性查看      |\n",
    "    | 兼容设备          | 可自动映射到CPU/GPU/Ascend等 |\n",
    "\n",
    "\n",
    "## YOLO 输出格式\n",
    "\n",
    "* **输出内容：** `检测框信息（边界框）`、`类别概率`和`置信度`\n",
    "\n",
    "* **格式：** 一般是一个二维数组，形状类似 `[N, 5 + num_classes]`，其中：\n",
    "\n",
    "  * N 是检测到的候选框数量（通常是模型预测的固定数量框）\n",
    "  * 5代表框的5个参数：`(x_center, y_center, width, height, objectness_score)`\n",
    "\n",
    "    | 参数名                   | 含义        | 说明                     |\n",
    "    | --------------------- | --------- | ---------------------- |\n",
    "    | **x\\_center**         | 边界框中心点横坐标 | 通常相对于图像宽度的归一化坐标，范围0\\~1 |\n",
    "    | **y\\_center**         | 边界框中心点纵坐标 | 通常相对于图像高度的归一化坐标，范围0\\~1 |\n",
    "    | **width**             | 边界框宽度     | 相对于图像宽度的比例或像素值         |\n",
    "    | **height**            | 边界框高度     | 相对于图像高度的比例或像素值         |\n",
    "    | **objectness\\_score** | 目标置信度     | 该框包含物体的概率，范围0\\~1       |\n",
    "\n",
    "\n",
    "  * `num_classes` 是类别概率分布（每个类别对应一个概率）\n",
    "\n",
    "* **后处理：** 模型输出的框还需要经过非极大值抑制（NMS）过滤重叠框，得到最终的检测结果。\n",
    "\n",
    "    > **NMS（非极大值抑制）的作用：**\n",
    "    > 去除目标检测中多个高度重叠的框，只保留置信度最高的那个，防止同一个目标被重复检测。\n",
    "    >\n",
    "    > **工作流程(了解)：**\n",
    "    > 1. 按置信度排序所有候选框。\n",
    "    > 2. 取置信度最高的框，输出它。\n",
    "    > 3. 删除与该框重叠（IoU超过阈值）的其他框。\n",
    "    > 4. 重复以上步骤，直到所有框处理完。\n",
    "\n",
    "\n",
    "\n",
    "    这样能让检测结果更准确，避免重复框。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    * 输入：一张RGB图，尺寸416×416\n",
    "\n",
    "    * 输出（未经NMS示意）：\n",
    "\n",
    "      ```\n",
    "      [\n",
    "        [0.5, 0.5, 0.2, 0.3, 0.9, 0.1, 0.8, 0.1],  # 框中心x,y,宽高,置信度, 类别概率(3类示例)\n",
    "        [0.7, 0.4, 0.1, 0.2, 0.75, 0.7, 0.2, 0.1],\n",
    "        ...\n",
    "      ]\n",
    "      ```\n",
    "\n",
    "    * 经过NMS后输出：\n",
    "\n",
    "      ```\n",
    "      [\n",
    "        {box: [x1, y1, x2, y2], score: 0.85, class_id: 1},\n",
    "        {box: [x1, y1, x2, y2], score: 0.72, class_id: 0},\n",
    "        ...\n",
    "      ]\n",
    "      ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba50873",
   "metadata": {},
   "source": [
    "# 进行图像对模型的输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3199cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入张量的形状: (1, 3, 416, 416)\n",
      "输入张量的数据类型: Float32\n",
      "张量示例数据 (第一个像素点RGB): [0.17254902 0.17254902 0.16470589]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mindspore\n",
    "\n",
    "def preprocess_image(image_path, size=(416, 416)):\n",
    "    # 读取图片，默认是BGR格式\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"无法读取图片: {image_path}\")\n",
    "    \n",
    "    # 调整大小\n",
    "    img_resized = cv2.resize(img, size)\n",
    "    \n",
    "    # BGR转RGB\n",
    "    img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # 归一化到0~1 ，将0-255 映射到 0-1之间的小数\n",
    "    img_norm = img_rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "    # HWC转CHW格式 以供模型支持\n",
    "    #(H,W,C)\n",
    "        # H = 高度（Height）\n",
    "        # W = 宽度（Width）\n",
    "        # C = 通道数（Channel，通常是3，即RGB）\n",
    "\n",
    "\n",
    "    img_chw = np.transpose(img_norm, (2, 0, 1))\n",
    "    \n",
    "    # | 原维度   | 新位置     |\n",
    "    # | 0 (H) | 放到第 1 维 |    \n",
    "    # | 1 (W) | 放到第 2 维 |    \n",
    "    # | 2 (C) | 放到第 0 维 |    \n",
    "    #把原来的 (H, W, C) 变成 (C, H, W)。\n",
    "    \n",
    "    #为什么这么转？\n",
    "        # 因为大多数深度学习模型（如 PyTorch、MindSpore）要求图像的输入格式是：\n",
    "\n",
    "            # (batch_size, channels, height, width)  # 即 BCHW 格式\n",
    "            # (channels, height, width)  # 即 CHW 格式\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    # 给图像数据增加一个批次维度batch，变成 (1, channels, height, width)\n",
    "    img_batch = np.expand_dims(img_chw, axis=0)\n",
    "    \n",
    "    return img_batch #返回\n",
    "\n",
    "def test_yolo_input_tensor(image_path):\n",
    "    img_np = preprocess_image(image_path)\n",
    "    tensor = mindspore.Tensor(img_np, mindspore.float32)\n",
    "    \n",
    "    print(\"输入张量的形状:\", tensor.shape)  # 应该是 (1, 3, 416, 416)\n",
    "    print(\"输入张量的数据类型:\", tensor.dtype)\n",
    "    print(\"张量示例数据 (第一个像素点RGB):\", tensor[0, :, 0, 0].asnumpy())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"test_by_yolov5s\\images\\images.jpg\"  # 换成你本地的图片路径\n",
    "    test_yolo_input_tensor(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c27aa94",
   "metadata": {},
   "source": [
    "# 进行模型推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e86226",
   "metadata": {},
   "source": [
    "### 先导入一个参数解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "914d109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=\"YOLOv5 MindSpore 推理脚本参数\")\n",
    "\n",
    "    # 图片路径或视频帧路径\n",
    "    parser.add_argument('--image_path', type=str, required=True,\n",
    "                        help='输入图像文件路径')\n",
    "\n",
    "    # 模型相关\n",
    "    parser.add_argument('--weight', type=str, required=True,\n",
    "                        help='模型权重文件路径 (.ckpt)')\n",
    "\n",
    "    parser.add_argument('--model_name', type=str, default='yolov5',\n",
    "                        help='模型名称，默认 yolov5')\n",
    "\n",
    "    parser.add_argument('--img_size', type=int, default=416,\n",
    "                        help='输入图像大小，默认 416')\n",
    "\n",
    "    # 数据集和类别\n",
    "    parser.add_argument('--num_classes', type=int, default=80,\n",
    "                        help='类别数量，默认80')\n",
    "\n",
    "    parser.add_argument('--dataset_name', type=str, default='coco',\n",
    "                        help='数据集名称，默认 coco')\n",
    "\n",
    "    parser.add_argument('--class_names', type=str, default='',\n",
    "                        help='类别名称列表，用逗号分隔，如 person,car,bike。若为空则用数字代替')\n",
    "\n",
    "    # 推理阈值\n",
    "    parser.add_argument('--conf_thres', type=float, default=0.25,\n",
    "                        help='置信度阈值，默认0.25')\n",
    "\n",
    "    parser.add_argument('--iou_thres', type=float, default=0.45,\n",
    "                        help='NMS阈值，默认0.45')\n",
    "\n",
    "    parser.add_argument('--conf_free', action='store_true',\n",
    "                        help='是否使用conf_free模式')\n",
    "\n",
    "    parser.add_argument('--exec_nms', action='store_true',\n",
    "                        help='是否执行NMS，默认执行')\n",
    "\n",
    "    parser.add_argument('--nms_time_limit', type=float, default=0.5,\n",
    "                        help='NMS时间限制，默认0.5秒')\n",
    "\n",
    "    # 其他\n",
    "    parser.add_argument('--save_result', action='store_true',\n",
    "                        help='是否保存推理结果')\n",
    "\n",
    "    parser.add_argument('--save_dir', type=str, default='./results',\n",
    "                        help='保存结果的目录，默认 ./results')\n",
    "\n",
    "    parser.add_argument('--ms_amp_level', type=str, default='O0',\n",
    "                        help='MindSpore 自动混合精度等级，默认 O0')\n",
    "\n",
    "    # 网络配置（简单示例，实际项目可根据需求扩展）\n",
    "    parser.add_argument('--stride', type=int, nargs='+', default=[32],\n",
    "                        help='模型步长列表，默认[32]')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7fb58d",
   "metadata": {},
   "source": [
    "# 模型推理\n",
    "\n",
    "关于**模型推理过程**，可以拆成几个关键步骤。简单说，就是：\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1. **模型定义（网络结构搭建）**\n",
    "\n",
    "* 先用代码描述神经网络结构\n",
    "* 框架根据定义创建模型实例，准备好各层\n",
    "\n",
    "### 2. **加载预训练权重**\n",
    "\n",
    "* 从训练好的参数文件（checkpoint）中读取权重\n",
    "* 将权重赋值给模型中对应的层\n",
    "* 权重加载成功后，模型具备推理能力\n",
    "\n",
    "### 3. **输入数据预处理**\n",
    "\n",
    "* 读取输入数据（图片、视频帧等）\n",
    "* 图像尺寸调整（resize到网络输入尺寸，比如640x640）\n",
    "* 数据归一化（如除以255转为\\[0,1]范围）\n",
    "* 颜色通道顺序调整（如BGR转RGB）\n",
    "* 变换成模型要求的格式（如NCHW，即batch, channel, height, width）\n",
    "* 转成框架支持的Tensor类型\n",
    "\n",
    "### 4. **模型前向推理**\n",
    "\n",
    "* 把预处理后的数据输入模型\n",
    "* 运行前向计算，获得输出结果（通常是多尺度预测框、类别置信度等）\n",
    "\n",
    "### 5. **后处理**\n",
    "\n",
    "* 对模型输出结果解码成边界框和类别标签\n",
    "* 使用非极大值抑制（NMS）去除重叠框\n",
    "* 过滤置信度低的检测结果\n",
    "* 转换框坐标回原图尺度\n",
    "* 输出最终检测框和类别\n",
    "\n",
    "### 6. **结果展示或保存**\n",
    "\n",
    "* 在原图上画框和类别标签\n",
    "* 保存检测结果（图片、文本、json等）\n",
    "* 或者用于后续的业务逻辑\n",
    "\n",
    "---\n",
    "\n",
    "## 总结流程图\n",
    "\n",
    "```\n",
    "输入图片\n",
    "   ↓\n",
    "预处理（resize/归一化/转tensor）\n",
    "   ↓\n",
    "模型定义 + 加载权重\n",
    "   ↓\n",
    "模型前向推理（得到原始预测结果）\n",
    "   ↓\n",
    "后处理（框解码、NMS、过滤）\n",
    "   ↓\n",
    "结果可视化/输出\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e016197",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m args\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m args\u001b[38;5;241m.\u001b[39mms_amp_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mO0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 102\u001b[0m \u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m, in \u001b[0;36minfer\u001b[1;34m(args, frame)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m输入图片路径无效或frame为空\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 2. 创建并加载模型\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m(\n\u001b[0;32m     22\u001b[0m     model_name\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m     23\u001b[0m     model_cfg\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnetwork,\n\u001b[0;32m     24\u001b[0m     num_classes\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnc,\n\u001b[0;32m     25\u001b[0m     checkpoint_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m     26\u001b[0m     sync_bn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     27\u001b[0m )\n\u001b[0;32m     28\u001b[0m network\u001b[38;5;241m.\u001b[39mset_train(\u001b[38;5;28;01mFalse\u001b[39;00m)  \u001b[38;5;66;03m# 设置推理模式\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# 3. 将预处理后的numpy转成MindSpore张量\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93a380c3",
   "metadata": {},
   "source": [
    "| 模块分类   | API名称               | 功能描述                       | 使用示例                                                      |\n",
    "|------------|-----------------------|-------------------------------|---------------------------------------------------------------|\n",
    "| 模型构建   | create_model          | 创建YOLO系列模型实例          | model = create_model('yolov5s', checkpoint_path='yolov5s.ckpt') |\n",
    "| 数据预处理 | letterbox             | 图像缩放填充预处理            | img = letterbox(img, new_shape=640)                           |\n",
    "|            | ImageListtoTensor     | 将图像列表转换为MindSpore张量 | tensor = ImageListtoTensor([img1, img2])                      |\n",
    "|            | create_dataset        | 创建训练/验证数据集           | train_dataset = create_dataset(args.data.train_set, is_train=True) |\n",
    "| 推理执行   | detect                | 执行目标检测任务              | results = detect(model, img, conf_thres=0.25)                 |\n",
    "|            | segment               | 执行实例分割任务              | masks = segment(model, img)                                   |\n",
    "| 结果可视化 | draw_result           | 绘制检测/分割结果可视化       | vis_img = draw_result(img, results, class_names=['person', 'car']) |\n",
    "|            | show_image            | Jupyter环境实时显示结果       | show_image(result_img, title='检测结果')                      |\n",
    "| 配置管理   | parse_args            | 解析YAML配置文件              | args = parse_args('configs/yolov5s.yaml')                     |\n",
    "|            | set_default_infer     | 设置推理默认参数              | set_default_infer(args)                                       |\n",
    "| 训练管理   | create_optimizer      | 创建优化器                   | opt = create_optimizer(model, lr=0.01, momentum=0.937)        |\n",
    "|            | YOLOv5Loss            | YOLO系列损失函数             | loss_fn = YOLOv5Loss(box=0.05, cls=0.5, obj=1.0)              |\n",
    "|            | create_lr_scheduler   | 创建学习率调度器              | lr_scheduler = create_lr_scheduler(lr_init=0.01, warmup_epochs=3) |\n",
    "|            | auto_mixed_precision  | 自动混合精度训练              | ms.amp.auto_mixed_precision(network, amp_level=\"O2\")          |\n",
    "| 设备管理   | sync_data             | 跨设备/云脑数据同步           | sync_data('obs://dataset/', './local_data')                    |\n",
    "| 日志系统   | logger                | 统一日志记录接口              | logger.info(\"Inference completed\")                            |\n",
    "|            | TensorBoardLogger     | 训练指标可视化                | logger = TensorBoardLogger(log_dir='./logs')                   |\n",
    "| 工具函数   | set_seed              | 设置全局随机种子              | set_seed(42)                                                  |\n",
    "| 数据增强   | apply_augmentations   | 应用数据增强流水线            | aug_img = apply_augmentations(img, mosaic=True, hsv_aug=True) |\n",
    "| 模型部署   | export                | 导出MindIR格式模型            | export(model, Tensor(input), file_name=\"model\", file_format=\"MINDIR\") |\n",
    "| 视频处理   | VideoStreamHandler    | 实时视频流处理                | handler = VideoStreamHandler(camera_index=0, frame_size=(640,480)) |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindspore_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
